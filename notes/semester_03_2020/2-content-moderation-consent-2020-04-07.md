# Data. Together. Let's read about it

## Content Moderation & Consent (April 7)

[ðŸŽ¬ **Recorded Call**](https://youtu.be/Sb9pJfypvfg)

## Intro
This topic covers factors that impact the content that we see. How do platforms balance freedom of expression versus consent to avoid offensive content, navigate algorithmic versus human moderation and curation, or incentivize different types of interaction? What are downstream effects of these choices?

## Readings
* Bijan Stephen for The Verge: "[Something Awful's Founder Thinks Youtube Sucks at Moderation](https://www.theverge.com/2019/6/26/18744264/something-awful-youtube-moderation-rich-kyanka-lgbtq)" (2019) - strategies for moderation from Something Awful's founder
* Casey Newton for The Verge: "[Bodies in Seats](https://www.theverge.com/2019/6/19/18681845/facebook-moderator-interviews-video-trauma-ptsd-cognizant-tampa)" (2019) - around outsourced content moderation & its impacts on the humans who have to view & judge the content. Would recommend:
  * From the beginning to "But for the first time, three former moderators for Facebook in North America agreed to break their nondisclosure agreements and discuss working conditions at the site on the record."
  * NOT RECOMMENDED: the middle of the article for this groupâ€“Â it's good reporting but needs a content warning for graphic descriptions (and the intro gets the points across)
* Jussi Passanen: "[Human centred design considered harmful](https://www.jussipasanen.com/human-centred-design-considered-harmful)" â€“ how good design principles applied to business sense can be harmful for humans, especially in the context of a livable planet
* **Choose one of the following** (their lengths vary):
  * Mark Scott for Politico EU: "[Why Banning Political Ads on Social Media Misses the Point](https://www.politico.eu/article/facebook-twitter-google-political-ad-ban/)" (2019) - argues that beginning to moderate content for advertising is the beginning of social media companies taking ownership/responsibility over user content generally
  * Niam Yaraghi for Brookings: "[Twitter's Ban on Political Advertisements Hurts Our Democracy](https://www.brookings.edu/blog/techtank/2020/01/08/twitters-ban-on-political-advertisements-hurts-our-democracy/)" (2020) - discusses the unequal impact of the ban on more vs less-well funded political groups and pushes for more detailed transparency measures
  * Kate Conger for the New York Times: "[Twitter Will Ban All Political Ads, C.E.O. Jack Dorsey Says](https://www.nytimes.com/2019/10/30/technology/twitter-political-ads-ban.html)" (2019) â€“Â contrasted with the Facebook hands-off approach and Google's selective approach
* **Choose one of the following** (their lengths vary):
  * Clint Pumphrey for HowStuffWorks: "[How Do Advertisers Show Me Custom Ads?](https://computer.howstuffworks.com/advertiser-custom-ads.htm)" (2012) â€“Â cookies and retargeting, notice tone
  * Cade Metz for the New York Times: "[How Facebook's Ad System Works](https://www.nytimes.com/2017/10/12/technology/how-facebook-ads-work.html)" (2017) â€“Â targeting factors that Facebook uses for ads, the inception of ads into a content stream, some treatment of the Russia issue
  * Cole Nemeth for Sprout Social: "[How the Twitter Algorithm Works in 2020](https://sproutsocial.com/insights/twitter-algorithm/)" (2020) before "How to turn off the Twitter algorithm" â€“Â a really short one just highlighting the factors involved
  * Will Oremus for Slate: "[Twitter's New Order](http://www.slate.com/articles/technology/cover_story/2017/03/twitter_s_timeline_algorithm_and_its_effect_on_us_explained.html)" (2017) â€“Â much more in depth (not just how but why and future directions) but pretty long
  * Josh Constine for TechCrunch: "[How Facebook News Feed Works](https://techcrunch.com/2016/09/06/ultimate-guide-to-the-news-feed/)" (2016) before "An Updated List Of News Feed Algorithm Changes"

*Optional bonus readings*
* Naomi Wu's experience with media manipulation & being "content moderated" off of several funding platforms she had used to make a living: [part 1](https://medium.com/@therealsexycyborg/shenzhen-tech-girl-naomi-wu-my-experience-with-sarah-jeong-jason-koebler-and-vice-magazine-3f4a32fda9b5) and [part 2](https://medium.com/@therealsexycyborg/shenzhen-tech-girl-naomi-wu-part-2-over-the-wall-and-into-the-fire-5e8efc5c1509) â€“Â this is very interesting and topical but too long to include in the required reading
* [Flame Warriors](https://www.politicsforum.org/flame-warriors/), if you'd like a lighter take, is a tongue-in-cheek characterization of the various types of people moderators encounter
* The end of the Casey Newton "[Bodies in Seats](https://www.theverge.com/2019/6/19/18681845/facebook-moderator-interviews-video-trauma-ptsd-cognizant-tampa)" article, from "Last week, I visited the Tampa site with a photographer." to the end, interesting additional perspective re trying to figure out how this stuff *should* be done

## Themes
* Power and who has it
    * Over what you see
    * Via influence achieved through platforms
* Consequences without intentions: influence of algorithms
* Are we "owed" platforms?
* Should we expect our privately held digital platforms to take responsibility
    * For equitable treatment of users?
    * For the fallout of their moderation choices?
    * For the jobs they contract out?
* Advertisements
    * Who sees them and why?
    * Who buys them and how much power do they have to target?
    * What guidelines are appropriate to set?
* Community & polity
    * Can you share a story of a sense of community you experienced solely through a digital platform?
    * How does your (regular? real life? family? chosen family?) community communicate? (What about your polity?)
    * If you changed (digital) platforms for communication, how would that impact your community?
    * What are guidelines your community uses in online spaces?
    
## Discussion
**KELSEY**: So if y'all are ready, I can launch into our reading discussion.

And I have some themes and questions in the hackMD that we share, which is now in the chat. And I wanted to open by asking if everybody could just go around and share the story, one story of a sense of community you experienced through a purely digital platform. So I think I want to frame today's discussion around how much our lives can be mediated by by platforms that are within or beyond our control, but digital platforms that have mechanisms for control kind of built in. I can start with my little story, which is, I spent a summer working at a website called Instructables, which isâ€” it kind of rose at the beginning of the maker movement. And it's this tutorial site where people log on and they make stuff. I really admire that this site, they're very specific about trying to have a kind of community that... they're very inclusive with their definition of "maker". One of the things that they have in their kind of makerspace/lab area, is that they're very careful to have a test kitchen. And the founder was talking to me about this: people who make robots and stuff, they know they're makers, but a lot of people who make stuff all the time just kind of consider it like maintainership work, or "women's work" type of stuff. Making in a kitchen is also making; making with a sewing machine is also making; making with wires is also making; making with code is also making. So I really admired that about that community and also their comment policy, which is literally "be nice". And as a user, you can flag a comment not just as spam or inappropriate, but as "not nice" to have it reviewed by a moderator. And that's the first time I ever felt like I had friends who I never met other than through their online presence because you get this sort of core of people who you kind of get windows into their lives because they post these step by step photo instructions for different stuff that they're making. And then they look at other people's and they comment and they show you that they made it too. Yeah, that's one community.

**KEVIN**: I can share next. Actually EDGI is the first time I've had community through digital platform because EDGI is completely distributed, so for a long time, like I only interacted with people either through Zoom, Slack, or GitHub. It's really amazing when you have consistent interactions through all these mediums that, a year later when I was able to attend an in-person meeting and was meeting folks for the first time in person, it didn't feel that way at all. It just felt like we had known each other for so long already but we were like wait, I've never actually given you a hug before! EDGI is continuing, going strong, and continues to be my community.

**LOURDES**: For me it is the Midwest 90s Emo Facebook group that I am part of. A few of us, the main posters in the group, have branched off, and we've created our smaller group that's private and we've become really good friends. Lately we've been having zoom calls with, like 20 of us. I've met a few people in different cities now. So it's sort of cool knowing I have friends across the country.

**DAWN**: I don't have a goodâ€” EDGI is that for me, but when you said that, I didn't think of a good recent example; I thought of an old one, which is probably an early one for me, which then I was thinking about in the context of these readings. I was really into modding Morrowind, so I was an active member of a forum called Tamriel Rebuilt, which was all about people who wanted to build this one mod, which was like rebuild the whole continent in the Elder Scrolls game Morrowind, which just had one little island of it, sort of a quixotic project that was maybe not possible in the constraints of the game engine at the time. I think they're still going. I actually just googled, they're still going, that mod is active if you want to play Morrowind again. That came out when I was in high school, so like a good 15 years ago.

I had been active in forums like IRC and stuff like that before, but that was one of the first places where I really got to know other peopleâ€”and kind of at a time where there weren't a lot of these remote collaboration tools, in the same way, so even the way I knew them is so different. And I think in a way I'm lucky to know people I work with remotely now. So I felt like I knew these people well, because we just posted in forums together, you know, and you kind of got to know who they were from that. Maybe it came a little bit to, like, say somewhat Something Awful was for folks. I just sort of eventually stopped making mods. That's kind of how I stepped out of that community. Which, in hindsight, feels a little sad.

**GREG**: I had something actually in mind. With Liz Barry I had been organizing this process of discussing this phenomenon of emergent, spontaneous, civic hacking disaster responders. And I just published this piece yesterday that that shares principles that we articulated for network-centric crisis response. My own experience during Hurricane Irma, I wasn't in Miami, which is where I'm from and where I am now, but I was watching the storm as it emerged and headed right at us and I set up a Slack. I saw a whole bunch of people talking about how the storm was coming, but in different forums. And so I set up a slack for people who wanted to prepare. And within a couple of days there were like, 700 or almost 1000 people in it. And they were doing all kinds of things. And I felt responsible for this space that I'd set up. And so I was working 18 hour days, to just, like, manage all the things that all these people were doing. But you know, a lot of which were actually like, not very good ideas. All really well intentioned, but a lot of times, people just came up with something and they're like, let's get to work. And let's, you know, put this data together and it was just like, Who did you talk to? Who said that was a good idea? You know, how, like, blah, blah, blah. And I just had a really challenging experience trying to organize this community and Slack. As fun as it was as it was coming together, I had very few tools at my disposal for sorting through noise and for evaluating the quality of different kinds of things that were going on. And it was only through connecting with other organizers who were experienced with this kind of community curation and network organizing that we got some measure of control by doing thingsâ€“ like, every channel should have a document that says what's happening in this channel, you know, at the top of the channel, and, you know, it was like we had to actually figure out how to make it work. And so I sort of walked away being like, I would like to help others learn from our mistakes so that they can make more interesting mistakes.

**KELSEY**: That's really interesting. That's a great transition, actually toâ€“ I wanted to make sure everybody had a moment of community community enabled by these types of platforms that they could kind of hold in their hearts as we talk about these articles, which are largely pretty negative, about what it means to do moderation. The topic is moderation in general in theory, but when I picked articles, I definitely focused on digital spaces and sort of power, control, responsibility, and what we owe to each other as participants. I really thought it was interesting, Greg, that you brought up the word responsibility so quickly. Do you still feel responsible to your community? I'm curious how you handled that, too, in terms of bringing on new moderators and such.

**GREG**: Absolutely. In the time, I felt responsible for the network that I'd convened, but also responsible to ensure that that network was accountable to members of the community. So I was spending a lot of my time going out and finding people who would never join our Slack, talking to them, and then bringing back that perspective into this platform. There must be a better way. That was partially why I wrote these principlesâ€“ I didn't write the principles, I facilitated these conversations and, but having something on hand to be like, this is why we're going to go to the extra effort to hear from somebody before we put this out into the world. People just like, you know, they're, they're in Slack, and they're seeing everybody in Slack. And when I'm talking about like, why are we doing this? It's like, well, we're all here, we're doing this. There, there wasn't really a framework for how do we locate this digital virtual community in some real world context, and I did feel responsible for bridging that gap. Which made me very popular in my own Slack.

**KELSEY**: Lourdes, do you want to talk about what you're mentioning in the chat?

**LOURDES**: Has anyone heard the podcast Last Podcast on the Left? It's a comedy podcast about murders and paranormal stuff and conspiracy theories. On my drive from Boston to Texas, I listened to like all the episodes, and I got really into it. And I joined the the group on Facebook and I started posting a lot. And then all of a sudden, little did I know, I became a moderator. And it was a whole world like, so there was a group of mods, and you know, we had our own group. So this was another extension group. And we have this chat and the mods on purpose chose people from, like, different perspectives. So, in the chat there were these far right dudes that were really into guns. And then there is me like, far left lady of color, who was totally like, on them all the time. And, but, you know, we have this sense of camaraderie, too. And we and even a group name for ourselves, it's so weird. But this was a job. This is like a couple hours a day. And thousands of people were in this group that we modded, so and so the the reading about Facebook, the Facebook moderators, I mean, that's a whole other level. But there is some stuff that people posted and I saw and I was just like, humanity, what is up with humanity. And why are we unpaid group mods for this group like, why are we doing this?

**KELSEY**: Would it have been better if you were paid?

**LOURDES**: I think so. I mean, I guess the the payment was like, being "in", being friends with these people and being the cool mod in the cool group.

**KELSEY**: Dawn, did you want to bring your chat into the conversation? There's not that many of us today. It's nice.

**DAWN**: First, just to acknowledge that that was a lot of labor, Lourdes. I know. Yeah, it takes a lot and a lot of time a lot of emotional energy.

Yeah, it kind of came up when I was thinking also about the Facebook article. And even the Something Awful one, which is like, or also you, I guess Something Awful touched on YouTube, it wasn't discussed, but kind of in the background in my mind was that really great article by James Bridle about like auto-generated content targeting children on YouTube, which is deeply creepy and disturbing. That came out a year and a half ago maybe. And Lisa Nakamura wrote this like article and thinking through this thing, which was like, we see these postings of all of this hateful, misogynist, racist, and deeply disturbing graphic content as aberrations. But what if we took that seriously as an expected outcome? So let's not treat it as an unintended consequence of what these platforms do. But read them as like, no, this is one of their products. And have that help think about how these spaces are built and maintained. Because I just don't actually know if I think that any of these models are sustainable when what they require isâ€“ I think what Facebook and YouTube and some of these big platforms are doing is basically trying to just throw as much cheap labor and people's dignity at a problem and hope that they're going to get good enough at automating from what they learn from that at the cost of all of these people's emotional wellbeing and see if that'll get them to a point where they expect that no one's gonna have to look at it, but I just don't think that that's going to work if you build systems that magnify or create it, where virality is encouraged. And so it's not just that one video gets posted once, it's that it gets posted hundreds of thousands of times as they mix and sort of flows through multiple channels. I just felt like that was a piece there, which wasn't explicitly addressed, but brought up in those articles. And then I like how Lisa Nakamura talks about it as a way to think about the design intentions.

**KELSEY**: Yeah, I guess I'm thinking of, like in junior high, everybody would share those videos, those GIFs that would just go on being peaceful and nothing for a long time and then suddenly, a scary face would pop out. And there was something so delightful about it to like every 12 and 13 year old that would cause that to go viral. Even though it was like kind of awful. In response to what you're talking about with the YouTube generation of content that appeals to young children, but is kind of horrifying to adults, my niece, whenever she got access to a phone for long enough, you'd look over and she'd just be like in that part of YouTube. And it's like weird stuff, like, adults or teenagers pretending to be babies. Just really weird, like, I don't know, but something about how disturbing that is or how unusual that is. There's got to be something biological about how attractive that is to somebody very young. And I guess I wonder if that comes back to the question of responsibility to moderate. The existence of Something Awful is interesting by itself, right? Or a 4chan, like there is an audience that's explicitly looking for the sorts of things that like I in my adult life would like to be moderated out of my feed.

**LOURDES**: As I see it, I have a couple of thoughts turning in my head. And I like well, first of all, I'm thinking of the internet, like when I was in middle school, and just how completely unregulated it was. You find really, really messed up stuff. I'm thinking of one website, I forgot the name of it, but it just has graphic images. I think this was like in 2001, 2002, during the war in Iraq. And it was just images from the war and a lot of other gross things, and and a lot of really messed up stuff that's not moderated. But I think you really had to... I was like a 12 year old stumbling upon it. It was pretty easy to get to. So this isn't a new issue. But what's new is the capitalism that is being prepared that it perpetuates and is being perpetuated by it. Like now, people make money off of this content in a way. These companies that are contracting with Facebook and exploiting their workers, there's a whole industry made from this messed up content.

**DAWN**: That end of the article about Cognizant, one of the last lines was pretty evocative about how it's a system where the people who work there thought, this is my first step into being a knowledge worker working at a tech company, but it's really Facebook controlling costs and risk by like outsourcing the messy work of finding and training human beings, laying them off all when the contract ends. Have the vendors hit some just-out-of-reach metric and let them figure out how to get there. In one way, I agree, it's nothing new, but it does feel like it's just such an acceleration of existing patterns. That model of outsourcing risk is an old pattern. That, when combined with the scale that some of these platforms are operating at, fine tuning that's happening on them for certain behaviors or types of attention, like that whole article on Twitter's introduction of their new algorithmâ€”they're all compounding into this acute state.

**KELSEY**: I wonder if there's been something fruitful, we could look at in the most profit-driven version of this, which is the the articles on advertisements. I think that what's really interesting, just to get into the advertisements slightly, is that unlike, say, the Facebook newsfeed or Twitter generally, we don't really have an expectation that advertisements should be equitable.

**GREG**: What do you mean by equitable?

**KELSEY**: I guess, Facebook and Twitter feel to a lot of people like they're supposed to be a public forum, even though they're very literally not. But an advertisement, you know that that's because somebody paid for it to be there. I think that there's a really interesting balance there, and I don't even have an article in the selection, I'm now realizing around like the ability to buy bots to promote your stuff as though they're people or to buy people to promote your stuff as though they're individual people.

**GREG**: Yeah, I mean, Facebook conflates, in its messaging on this stuff, it conflates the concept of freedom of speech in multiple directions. First of all, freedom of speech just means like, the government can't arrest you. The First Amendment does not apply to Facebook. Facebook can choose whatever policies it wants. So for them to say "free speech" is not really coherent. And and then yeah, like they hide behind free speech. To defend their position on allowing deceptive political advertisements.

I have some friends who've worked at Facebook for a very long time, like since the mid aughts, since the beginning. And I've argued with them about this stuff for a long time. And those arguments over the last five years have become really touchy. But it's worth at least understanding where they're coming from. From their perspective, they have this pseudo-sophisticated view of human nature as like, A) yes, humans are flawed, and so bad things are going to happen on Facebook, but B), the marketplace of ideas is inherently good. And so though there are bad things that happen, on net, freedom of speech, people being able to say whatever they want, is good, right? It all it's all going to work out in the end, and trying to like, curtail freedom of speech, they're like, well, who gets to decide what's true? From my perspective, I'm like, that's a really interesting question. It would be worth asking that question. Let's have that conversation, as opposed to it just being like, haha! hard question to answer, so therefore, end of story. But it is really worth thinking, and I don't know, I don't necessarily have ready answers as to, how should they beside what constitutes truth. But like, it is hard, right? I don't think it's as irreconcilable as they make it out to be. But I think their perspective is bad, and I would like to see other opportunities to demonstrate that there really is a coherent alternative to the civil libertarian "there's nothing we can do" approach.

**LOURDES**: There's a really good book that is relevant to this conversation called Words that Wound, and it's about hate speech, especially in a university setting, and it's in response to this whole libertarian idea that all speech should be free, with the argument that words can be violent, they have a physical impact and especially when it's a racist or homophobic slur or diatribe, it can actually affect someone's livelihood

**KELSEY**: I very nearly but didn't quite include an article in the reading list around the punching of Richard Spencer.

**GREG**: Yeah, that was effective, right? For all that hand wringing about punching fascists, the fascists were like, every time we go into public, we get punched, so we're gonna stop doing that. I think. It seems like he doesn't go into public anymore, right? It was effective.

**KELSEY**: Yeah, I would like to see a retrospective take on that, actually. It was really hot for a minute.

**LOURDES**: If you're doing violence, you're gonna get violence in return. I'm sorry. It's like, at that point, it's defense to punch him because he's just such a violent character.

**KELSEY**: I guess I'm curious how platforms play into this discussion of violence and public forums and freedom of speech. Do you think that if Facebook and Twitter didn't appear to be such big civic forums, do you think that we would request one from the government, a digital space to discuss things?

**DAWN**: There are various governments that have attempted to create those sort of platforms, but they tend to be a capture for consent or, you know, resistance to ideas. Canada is a very consultation-heavy country. So we get consulted a lot using consultation platforms. I think there's other countries that have models like that, like Decidim, on a different scale in Barcelona, I know Greece had a way that they were doing these online consultations, but like, not necessarily in this model of like a public forum that maybe Twitter operates at now and Facebook. But those places were not that in their original intent, right? One of the articles you posted shows that sort of shift in Twitter. And I think the history of Facebook is also a history of shifting and the way that Zuckerberg reformulated their mission multiple times, I guess, like sort of reflects his changing thinking on what their goal is. I think now it's supposed to connect the entire world, right? So the question about like, would people demand it, I don't know. I think that's a different model of how identities get performed or articulated at a nation level, probably not, because a lot of those are fictions anyway that are stitched together by a variety of forces. But I think that there have been very powerful more regional ways that there has been bottom up, wanting of that kind of space. But also to bring in here is the nationalized efforts, right, like people who want to nationalize some of these larger things, and/or break them apart, or the activist stakeholders who basically want to buy out Twitter and make it a platform co-op. I think there's some interesting ideas circulating around converting those spaces.

**GREG**: Do y'all have experience with the decentralized alternatives like Mastodon? Because I tried. It wasn't so much fun.

**LOURDES**: Oh, wait, I did try, yeah!

**KELSEY**: Wait, Greg, what was not fun for you?

**GREG**: It wasn't actually clear how to how to do it. I managed to do it after, like a half hour, I managed to join a, you know, a little group or whatever, like a node or an instance, I couldn't figure out how to see people on other nodes or how to communicate with them. I believe deeply in the concept of federation, right, and decentralized networks and so on, but I couldn't figure it out! If you had a community that you went there and built on, and you like, just made it work for a specific community, it seemed promising, but yeah, it was hard for me to imagine it catching hold.

**KELSEY**: I totally understand. I have been on Mastodon since I think 2015, and I have sub 100 followers there and no one responds to anything I do, and I don't know anybody there. When you make a new Twitter account, in order to get followers, you go out and you follow like 1000 people. On mastodon, I tried to do that, and it was just like, I got nothing. But I wonder if that's what's powerful about Slack for people. You can have Twitter lists and other kind of subcommunities and subforums. But I've been I was trying to think of, like, semi-decentralized, even though it's proprietary, platforms for creation of community. And I feel like that's been Slack for a lot of people. I'm in a space called We All JS, which is a Slack community for like explicitly inclusive for different identities who do JavaScript. And they have a bunch of kind of special moderation bots and rules where if you say something, you say "you guys", for example, Slackbot will respond and correct your language, which is something that Slack explicitly enabled, for you to set up that kind of interaction. I wonder if that's actually more decentralized than Mastodon because you don't have to be a deeply committed decentralized technologist to use it.

**DAWN**: I mean with Mastodon there's a really interesting I mean, tension there. I think there's been two waves of moves to Mastodon, which opened up some questions around it. Gab switched to using it last summer in July so the alt-right/far right had a space everyone who got deplatformed from Twitter went to build their space so they could be white supremacists. They had a different underlying tech stack, and they switched to using Mastodon servers, but like with sort of more selective roles on how to federate them, and that spawned this whole crisis, or maybe just a question, within the Mastodon community, of, do we want to federate these things? But they came as a community to that space. And so I think that became rather self-contained and functional fairly quick to those people who were kind of it was like an in-group that wanted in-group connections. There was another one more recently, I think, at the beginning of this year, where there was a lot of censorship going on in India, and a bunch of journalists actually all made a move collectively to Mastodon at the same time and were trying to think about censorship resistance and what these federated and decentralized alternatives offer. I think that opens up some of these questions around how moderation or how content works, or when there aren't one in these federated models: what some of these questions mean when there isn't a universal view, unlike Twitter, where like, you know, extensively I should I can access unless someone blocked me. And I'm logged into the platform. In many ways, I have a view that can be pretty universal of a whole platform space. But that is actually something you can definitely play with in something like Mastodon and if you come as a community, maybe it's a good community, or maybe it's a community that the existing Mastodon users don't want. You can kind of choose, I think, how porous that boundary is in and out of you. I mean, this issue has come up as well with Scuttlebutt, SSB, right. So they had some pubs where people were blocking, but the issue with how content is syndicated is people were worried that, without them seeing it, they were still syndicating content from pubs that were like, I guess kind of like anarcho-capitalist/libertarian veering into more right-wing, and I think some of the users or devices' identities, were doing alt-right or white supremacist content. So there's a lot of things there that I think are so interesting around moderation that these federated and peer-to-peer models open up.

**KELSEY**: I'm a bit curious if folks hereâ€”so, my partner is also very into the decentralized web. And so when we one-on-one chat, it is typically through Riot, which is by Matrix and decentralized, even though It is significantly less reliable than our former platform Facebook Messenger. And I've also tried to get my family over on to Signal for our group messaging. Partly because Signal is, you know, better than using Facebook for a lot of reasons, but also partly because I just want it to work on my laptop, and I can't if they're not on it, and everyone but my sister, by the way, joined. I don't know why she wants she doesn't know why either. But I'm curious if you guys have made that kind of decision with your families or communities on which platform to be on, and why.

**LOURDES**: For a while, I was like, only message me on Signal, but now I don't have a smartphone. So.

**GREG**: 
I did actually get my family on Slack a few years ago, which they resisted until they figured out how to embed animal GIFs. They were so mad that I was trying to get them to use this tool. And then once they saw that they could share GIFs everybody took to it. And there's like 30 channels.

**DAWN**: Yeah, I work with a lot of different people. And I try to collaborate with a lot of people who are very value driven in how they work with technology. So think these questions about, like, how far down our own stack, or what are our tools that we use, comes up a lot. So in one organization, our main space is Matrix, I use Riot, so Matrix chat, and it's always walking that tradeoff with like proprietary versus open and decentralized alternatives. And that is probably also true in my personal life. I have a lot of Signal groups, but also WhatsApp ones. And I'm just not on some platforms, like Facebook. But I think with all the mutual aid stuff going on right now, it's kind of been on my mind a lot more. So I started like a pod in my building, and we're using WhatsApp. It's that perennial organizing problem: you have to go where the people are. I think a lot of that model, too, is also one of harm reduction, not Puritanism. You can't be like, no, we'll only talk if you first install x new tools and I don't know air gap your machine to generate your key, you gotta be like, okay, let's get working, but let's start thinking actively about how to reduce risks to ourselves and what risks we face as a individual or small group or community. I think you're seeing that right now with Zoom: all of this stuff around this sort of this little misleading 'e'. This is not end-to-end encrypted! Just sayin'. And/or privacy and some of those tradeoffs. I think that's an active tension. It's not something to be resolved. I think it's probably just often something to negotiate.

**LOURDES**: And the other thing is, WhatsApp is global, and it's integrated with our cell phone numbers. But then it's owned by Facebook. Yeah, so going with what you're saying, Dawn, it's a whole tension that we have to face. But WhatsApp is pretty useful.

**KELSEY**: I had some interesting conversations with my mom around what gets communicated over different spaces. I was trying to convince her to try Scuttlebutt. I don't remember why. I don't, in retrospect, think it would work super well for her, due to having no friends on Scuttlebutt. But she was talking about how on Facebook, there's a lot of stuff that she just doesn't bother posting anymore, which I think is generally true for people: once you get past a certain number of friends, you kind of don't want to post anything anymore. Or, not anything like real or raw. I guess I've been thinking about how we self-moderate on these platforms and how that kind of interplays with the moderation that's built into the platform, or how these platforms I guess nudge us to behave in certain ways towards each other.

**LOURDES**: I have a meme that I'm gonna find that addresses this question. I can't find the good meme, but this is... the 16 candles one.

**DAWN**: It has, what's his face? Emilio Estevez's character is Twitter. Molly Ringwald is Instagram, and then what's his face is LinkedIn. My Instagram is, I just have friends there, so I can let loose. And then my Facebook is like, just everyone in my life. So I keep it pretty restrained unless I'm in my special private groups. Even though all my data is on there, but yeah, we mold different platforms to different aspects of how we want to present ourselves to the outside world, to our audience. There's all this performativity in internet life.

**KELSEY**: I'm trying to figure out a way to frame this conversation around ways that we could take power over these spaces. And it's very difficult. Because it's like, I can't suggest anything, you know?

**DAWN**: I mean, I think that's again, I just been really interested. This is not my project, but were I in the mood to suggest research projects to people, I actually think revisiting what moderation means, in some of these shifts in peer-to-peer systems that authenticate identity per device as opposed to in some other ways, but you verify it, is quite interesting. thing. So like, you know SSB, you generate a keypair, it's tied to a device. So you see people have multiple identities on SSB that are actually just like, this is my phone. And I don't do it, but it'd be like dcwalk-laptop, dcwalk-mobile, or something. And what gets I get like identified with you or associated with you, and what "you" is, when that changes, I think that really opens up how you want to think about some of these questions of moderation. And they actually have a really lovely, you know, I don't know, if you if any of you have read, I don't know if this was a previous reading topic, the principles that the Scuttlebutt community has defined but they have this concept where they talk about near moderation, in the, I think is right beside where they talk about interdependent abundance, which is also lovely. So yeah, like I say, I think they're really trying to get at opening up some of these topics from a very different angle that maybe comes from different architectural choices, but I think can speak back in cool ways too.

**KELSEY**: That's really interesting. That would have been a great reading. It reads as maybe directly coming out of influence from Enspiral, if you know them.

**DAWN**: Yeah, there's a lot of overlap there, in terms of early people in Scuttlebutt and Enspiral. The other thing I would say is like a power take-back mechanism that comes out of some of the mutual aid stuff is like just even visibility, right? I think people have flags, when people are going and doing this more pod-style or neighborhood-level collaborating and working to each other, like those don't surface or get brought up on a single platform, the model that Facebook is perpetuating is this universal space. I think that many scholars have really, very convincingly critiqued that what the problem is with was framing or designing for a universal, and I think that that model doesn't work. So I feel like thinking about ideas like federation probably are better represent a more pluralistic approach to like, a lot of different people all over the world connected rather than like a universal platform.

**LOURDES**: So what does Federation mean?

**DAWN**: I've been talking a lot. I can do an explanation, but I know Greg, you said you're interested in it. So do you want to?

**GREG**: Federation, as I understand it is like, you have a lot of different semi-autonomous systems that are a part of one system. One distinction that I think is really important, although sometimes I think these get fudged, is the difference between federation and confederation. A confederation is sort of like allies who aren't necessarily formally bound to each other. Whereas federation is like, actually, we are members, we are bound by specific set of rules. Sometimes that distinction, I think, when talking about networks, is not always so clear. The United States is a federation of states. The states have their own governing scopes and processes, but the federal government sets some standards and does some things on their behalf, collectively. And so, a federated network, it's not always clear to me whether a federated network is like, whether there issome sort of central organizing entity, or whether a federated network just means, like, there are different nodes that can communicate to each other using common protocols, but they're not necessarily actually bound through some sort of central coordinating entity.

**LOURDES**: I'm just thinking Star Wars.

**GREG**: Like the Empire versus the like the Federation. From like, the first three episodes.

**LOURDES**: Yeah, like the Galactic Federation, they communicate with each other, but they usually stay out of each other's business unless it's to defeat the Empire.

**GREG**: Yeah, I think Star Trek, as well like Star Trek has highly functioning Federation.

**LOURDES**: Wait, is that the Galactic Federation?

**DAWN**: No, that was Star Wars but there's different federations depending on where you are in the Star Wars timeline.

**KELSEY**: But I do think that's actually a really valuable point. Especially, like, Greg, what you're talking about with not being sure in a decentralized technology context, whether we really did mean federated in the sense of having some powers delegated to a unifying authority. I think that's super interesting. I don't hear that discussed much.

**GREG**: I'm really interested in how Americans seem to have lost the capacity to understand the concept of federation. Like, Americans do not understand this concept. And when you talk about federation, it makes them very uncomfortable, I find, which is so bizarre because like, we were the first to really do it. Not the very first. The Native Americans actually did it before us, but like, that's the whole American idea, is that you have local, state, federal, and and we just don't really understand that culturally anymore.

**LOURDES**: Do you think it has to do with how we see subjectivity and shared values? In my mind, a federation would be held together by shared values, but in the US, we're so into subjectivity. And you know, the idea that there's no universal morality, but it's like Dude, there is. You know, hurting other things and people is not moral. But yeah, I think it's the shying away from it just like with the freedom of speech thing, with colorblindness, shying away.

**GREG**: It's really interesting that you hone in on values there. I study the commons, governing the commons, the whole field of common pool resource management that's largely associated with Elinor Ostrom, the Bloomington school, and in the last 10 years, there's become a subfield that focuses on knowledge commons and digital resources as commons even though traditionally these are these are fields that study, like, watersheds and fisheries and woodsheds, natural resources systems, but there are definitely some similarities. But the tricky thing is when it comes to digital commons, for about 10 years, I think the open source field had a lot of hype and tooted its own horn a lot, but got a lot of things wrong. And I was finding that as an organizer who was totally sold on the "here comes everybody" Yochai Benkler, The Wealth of Networks approach. And then once I started doing these projects, I'm like, this is all like, this doesn't work. And I was trying to figure out why, and when I started reading Ostrom's stuff, which is super technical and jargony and boring, and it's also like the most important stuff, she has a set of principles for the design of institutions that can sustainably share resources. Principle number one is boundaries. And this was really tricky for open source and open knowledge communities to wrap their heads around. And when I was talking about Ostrom's work like with real anarchist hacker types, they just get immediately turned off by the notion of boundaries, because the whole idea is like, a network is more valuable if more people are in it, so how would you set up boundaries? And I actually think that the key is to understand that the values set the boundaries. The values help a community determine what's in and therefore what actually must beâ€”even though this is an open network, if you're not in line with these values, then you're out. And we have mechanisms to remove them.

**KELSEY**: I'm resonating a lot with that. And I'm trying to figure out which part of that to discuss. One of the things that I see in in open sourceâ€”I'm a lapsed maintainer of an open source project called Tessel, which is hardware which people are continuing to buy, but I think I might be the most active maintainer, which is not good. And there's a sense of responsibility that is hard. But then there's also this sense of, like, we really did have this very embracing approach to maintainership. Which is to say anyone could show up and say, hey, teach me how to use GitHub so that I can be a contributor and we did this sort of radical yes to that. But I would definitely not recommend that to your average open source project. And I think I've talked about this with Rob within EDGI a bit, but different open source projects have different meanings when they say open source, and that's okay. It has to be okay to say that, because the maintainer is notâ€”first of all, the maintainer is typically not getting paid. It is not their job to, A) make your feature, B) accept your pull request, C) listen to you talk about what you do and don't like about the thing they gave you for free. Open source can just mean I let you see it; open source can mean I let you suggest things but not contribute; it can mean I let you contribute; it can even mean I help you contribute, but that substitution is frequently not made. And I think part of that has to do with it being still kind of a new field. But part of it also has to do with people coming in with too much idealism. And I say that with a cringe in my body. But boundaries matter a lot. If you can't make any, you don't have anything meaningful inside of them.

**LOURDES**: I'm thinking about the beginning-of-the-internet stuff. Like I'm sure people have read You Are Not a Gadget, that book by Jaron Lanier, and the whole idea that the internet was some sort of anarchist idea, or vision, that then became co-opted by capitalism and by our ideas of what a computer interface should look like, of a group of people's idea of what a computer interface should look like is what people are in are now interacting with for, now, decades, like the whole idea of a file folder, the fact that we store our information that way. And I don't know where I'm going with this, but I think having no boundaries or set of principles going in, allows other principles to take over. I think that's how a lot of the technology we've built has become co-opted by systems of surveillance and advertising and capital.

**DAWN**: I mean, I think with some of that stuff around early networks, there's also historiography around how ARPANET and internet unfolded is like really gnarly as something that I've been reading a lot about for my dissertation, but I think that there's also just a way that it unfolded that actually speaks to kind of having an intentional flexibility that got kind of like recast in ways that were maybe unintended. And so I do think that there was sort of like an underdefinition of certain values that allowed them to be kind of empty buckets that could be filled with a lot of discordant things. And I think that that is a hard problem, or that's a problem that I'm interested in, is sort of these projects that are very value-driven, but still use these like flexible terms like decentralization, which kind of like stands in for multiple different values. But it's sort of like thinking about how you pair that with other values that actually give shape or a definition or a trajectory to your work or actually speak to the types of social change that you're pursuing, that is what I'm interested in.

Kelsey, I was just wondering, I was thinking about when you were shaping these readings, I was wondering about how you were thinking about, I guess, power and moderation and community. Or if there's another piece of that, that it feels like we haven't touched on yet. Just thinking about how you maintain spaces at a much smaller level. There's a lot of "moderation" work that never counts as moderation work, which is actually just maintaining social ties. And I guess that was something that was in my mind, is what is formally or has to formally be understood around moderation, and what are these other ways thatâ€” you talked about consent, or I think that's in the titleâ€” if there's something you want to touch on that.

**KELSEY**: Yeah. Actually the one article we haven't really touched at all is Human Centered Design Considered Harmful.

**GREG**: Hell, yeah.

**KELSEY**: This is so interesting. I'm excited that there is an article about this; I was expecting to have to go and look for articles around how, like, notifications and badges and stuff draw from casinos. Are you familiar with this?

**LOURDES**: I didn't know that.

**KELSEY**: Like, there's there's addictive design patterns that are built into a lot of different apps and notification styles. I think someone recommended this one in GitHub and said, maybe even you, Dawn, around around human centered design, and how things that beginâ€” I don't know, I'm seeing the broader pattern of things that begin with these really genuine intentions, like the creation of a community that needs to talk to each other, can turn into these crazy things when with these other interests, influences, and, you know, people, when people get involved, it gets messy, but also when money gets involved, it gets warped in this weird way. What did you guys get out of this?

**GREG**: Yeah, I've been waiting for an article like that for a long time I find the user-centered design discourse maddening. Which isn't to say it can't be useful as a tactic for a certain phase of a process, but it seems to have been a huge miseducation for an entire generation of would-be do-gooders, to just like, be like, well, we just have to think about, like, who the specific user is and how do we design for them, and it just involves this whole process of simplification. I understand the objective of that process, but when you're dealing with things like infrastructure and complex systems, that process of simplification is a process of erasure. And it's eventually going to come back to bite you in the ass. You're probably going to fail, or if you succeed, you're going to end up becoming a part of somebody else's problem. By just starting with human centered design principles. I just shared this set of principles that I found last month, society centered design principles, which may be a helpful corrective, although I really only read through it once, but I was like, yeah, this is what I want to see in the world.

**LOURDES**: Also, I just received Sasha Costanza-Chock's book Design Justice, and I started reading it, and I think their argument is right on point, and we've been drawing a lot from it in EDGI with the Environmental Data Justice group, that design really needs to happen from the bottom up instead of top down and through capital surveillance. But what also resonated me with it was his argument about anthropocentrism. That this, you quote, Human Centered Design is anthropocentric and ignores everything else in the world. It reminded me of a geographer, I forgot who it was. And it's a jumble in my head, I can't really articulate it, but like, turns the ideas of anthropocentrism on its head, and critiques the whole mainstream environmental movement as anthropocentric, because with ecological systems, it's saying, we need to take care of the wild and of the wilderness because we're humans, and we need to survive instead of looking at environmental justice issues, which is not anthropocentric. It's more society-centric. I'm going on a tangent, but I think what's weaving these together is this idea of a collective moving towards collective-oriented design and thought, in decisions as opposed to individual and alienated decisions that will destroy the world.

**DAWN**: There's been some really good critiques of user-centered design. I think a lot of design scholars would also, more broadly than these narrow terms like human-centered, user-centered, that just like speak to in design, especially kind of coming up with some industrial design, an operationalizing tendency, which turns focus to product and then like thinks about an individual engagement with the product as the site to design for.

That Design for the Real World book is like an early hot take, which is pretty fun. You see in the way theory or ideas around design get developed, I think Don Norman is like the seminal figure in design thinking and that sort of space, like kind of took a theory from psychology like affordances, about a relational approach, ecological psychology I guess. And then narrowed it down to this narrow way you think about an individual perceiving or having seen these affordances in an object. So I think there's this tendency that I actually don't know if we're at a good point to unwind. But there's a lot of really cool ways in, where people are trying to challenge that. Thinking about say, like, Sasha Costanza-Chock's work, and so Design Justice and that very participatory approach, there's that lineage of participatory design, and workplace studies stuff, which was super rad starting in the 60s and 70s. I think this is really hard. This, to me is like a thing where there's a lot of people kind of coming at it, but there aren't ways through yet that I think are reproducible. They're these micro-moments, but I don't know if we've escaped the gravity well that is getting trapped in designing a specific product. And when you have to design a thing, you just fall back on those patterns. I don't know, I found myself doing that when I do project management work. You're like, okay, let's write user stories. Personas. You just start doing that thing just because you need to move forward.

**KELSEY**: That's definitely something we've talked about before in these discussions, is that sense of a need for momentum. And we know that we need it to stay motivated at things. But it can be the most harmful thing we do, is like, make progress intentionally. On the other hand, I get really frustrated with the bottom-up design question and the decentralization question. We can say that it's good theory all we want, but how do you deploy a thing like that without without starting at the top, I guess?

**DAWN**: Trans-local, non-hierarchical distribution. That's it. That's the way. I actually think there are, again, the glimmers of really cool processes around that. They don't scale, because scale is part of the problem, there's a tension in that that's not resolved.

I was also gonna say I said in the chat, so the Toronto node of the design Justice Network is starting to do a read along of the book. I think we're doing like a chapter a meeting. Garance at EDGI, known to you all in EDGI, is, I think, kind of leading it with Victoria, who is an old Design Justice Network person. There's a crew in Toronto. And it's all online now obviously, because of the moment we're in, so easily joinable. And part of what some of the design justice people are doing, which I think is cool, is doing this like reflective process of projects they work on, applying or thinking through the design justice principles, and doing a retrospective. So I feel like that is a nice model for trying to notice that lag and do rethinking work, trying to weave back principles and practice.


## Chat log
00:04:41	D Walker:	sorry I missed what's going on but hoping things are okay as can be Kevin <3
00:07:54	Lourdes Vera:	totally added 1 cent!
00:11:24	Kelsey Breseman:	https://hackmd.io/oEcuKALCTi-PbawLmT_Ixw?both
00:18:25	Greg Bloom:	https://medium.com/@greggish/introducing-the-principles-of-equitable-disaster-response-89f0e2b44de9
00:21:18	Lourdes Vera:	I forgot to mention I was a mod for the last podcast on the left group on facebook and it was crazy
00:25:38	D Walker:	I always think of that Lisa Nakamura article about Glitch Racism in the context of the kinds of content that gets posted
00:25:43	Kevin:	Sorry all, gotta cut early, but so nice to see friendly faces for a bit and nice to meet you, Greg. Thanks for joining!
00:26:59	Kelsey Breseman:	omg my niece seriously got into that stuff too
00:27:07	Kelsey Breseman:	sheâ€™s 5 now
00:54:53	Lourdes Vera:	https://www.pinterest.com/pin/747245763149860665/
00:58:34	Kelsey Breseman:	https://scuttlebutt.nz/docs/principles/
01:08:11	Greg Bloom:	Through a series of â€œSustainOSSâ€ events, I helped develop these principles for open source community governance (based on Ostromâ€™s principles for governing the commons): https://docs.google.com/document/d/1OLjzRT9u-vjswnVj4AVYtmI8-eYkQPszigkYEkzcH-k/edit
01:09:41	Kelsey Breseman:	oh wow maybe I met you at the SustainOSS event at Github a long time ago?
01:11:06	Greg Bloom:	oh yeah! the first one!
01:14:34	D Walker:	There are a bunch! And some great old design crank takes on this!!
01:15:25	Greg Bloom:	Have yâ€™all seen these, i think it just came up recently - https://societycentered.design/
01:17:21	D Walker:	Lourdes! all! the design justice toronto node is doing a chapter a meeting read-a-long!
01:19:47	Lourdes Vera:	I wanna come!
01:23:28	Kelsey Breseman:	that would be really cool! Want to send out over the mailing list?
01:24:59	Greg Bloom:	@greggish